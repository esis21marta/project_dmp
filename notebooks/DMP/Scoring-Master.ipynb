{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta, date\n",
    "\n",
    "import pyspark\n",
    "import pyspark.sql.functions as f\n",
    "import pyspark.sql.types as t\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.window import Window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "conf = (SparkConf()\n",
    "        .setMaster('yarn-client')\n",
    "        .setAppName('scoring-master-table')\n",
    "        .set(\"spark.driver.maxResultSize\", \"10g\")\n",
    "        .set(\"spark.driver.memory\", \"16g\")\n",
    "        .set(\"spark.driver.memoryOverhead\", \"4096\")\n",
    "        .set(\"spark.dynamicAllocation.enabled\", \"true\")\n",
    "        .set(\"spark.dynamicAllocation.initialExecutors\", \"1\")\n",
    "        .set(\"spark.dynamicAllocation.maxExecutors\", \"75\")\n",
    "        .set(\"spark.dynamicAllocation.minExecutors\", \"1\")\n",
    "        .set(\"spark.executor.cores\", \"4\")\n",
    "        .set(\"spark.executor.memory\", \"16g\")\n",
    "        .set(\"spark.hadoop.fs.permissions.umask-mode\", \"002\")\n",
    "        .set(\"spark.kryoserializer.buffer.max\", \"512m\")\n",
    "        .set(\"spark.shuffle.service.enabled\", \"true\")\n",
    "        .set(\"spark.sql.broadcastTimeout\", \"1000\")\n",
    "        .set(\"spark.sql.hive.convertMetastoreParquet\", \"false\")\n",
    "        .set(\"spark.sql.parquet.compression.codec\", \"snappy\")\n",
    "        .set(\"spark.sql.shuffle.partitions\", \"1000\")\n",
    "        .set(\"spark.sql.sources.partitionOverwriteMode\", \"dynamic\")\n",
    "        .set(\"spark.yarn.driver.memoryOverhead\", \"4096\")\n",
    "        .set(\"spark.yarn.executor.memoryOverhead\", \"4096\")\n",
    "        .set(\"spark.yarn.maxAppAttempts\", \"2\")\n",
    "        .set(\"spark.yarn.queue\", \"root.hue_dmp_prod\")\n",
    "        .set(\"yarn.nodemanager.vmem-check-enabled\", \"false\")\n",
    "        )\n",
    "sc = SparkContext.getOrCreate(conf=conf)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master Table Weekstart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>Note: Update the weekstart before running the Split</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the weekstart before running the Notebook\n",
    "weekstart = (\n",
    "    (date.today() - timedelta(days=3))\n",
    "    - timedelta(days=(date.today() - timedelta(days=3)).weekday())\n",
    ").strftime(\"%Y-%m-%d\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaffold_path = \"hdfs:///data/landing/gx_pnt/mck_dmp_score/02_primary/scaffold_weekly.parquet/weekstart={weekstart}\"\n",
    "internet_app_usage_path = \"hdfs:///data/landing/gx_pnt/mck_dmp_score/04_features/internet_apps_usage/fea_internet_apps_usage.parquet/weekstart={weekstart}\"\n",
    "revenue_path = \"hdfs:///data/landing/gx_pnt/mck_dmp_score/04_features/revenue/fea_revenue.parquet/weekstart={weekstart}\"\n",
    "recharge_1_path = \"hdfs:///data/landing/gx_pnt/mck_dmp_score/04_features/recharge/fea_rech_full_topup_behav.parquet/weekstart={weekstart}\"\n",
    "recharge_2_path = \"hdfs:///data/landing/gx_pnt/mck_dmp_score/04_features/recharge/fea_rech_full_chg_pck_prchse.parquet/weekstart={weekstart}\"\n",
    "recharge_3_path = \"hdfs:///data/landing/gx_pnt/mck_dmp_score/04_features/recharge/fea_topup_behav_full_acc_bal_neg_or_zero.parquet/weekstart={weekstart}\"\n",
    "handset_path = \"hdfs:///data/landing/gx_pnt/mck_dmp_score/04_features/handset/fea_device.parquet/weekstart={weekstart}\"\n",
    "voice_calls_path = \"hdfs:///data/landing/gx_pnt/mck_dmp_score/04_features/voice_calls/fea_inc_out_uniq_bnums.parquet/weekstart={weekstart}\"\n",
    "internet_usage_path = \"hdfs:///data/landing/gx_pnt/mck_dmp_score/04_features/internet_usage/fea_internet_usage.parquet/weekstart={weekstart}\"\n",
    "cust_prof_path = \"hdfs:///data/landing/gx_pnt/mck_dmp_pipeline/01_aggregation/customer_profile/customer_profile_weekly.parquet/weekstart={weekstart}\"\n",
    "sms_1_path = \"hdfs:///data/landing/gx_pnt/mck_dmp_score/04_features/sms_2/fea_text_messaging.parquet/weekstart={weekstart}\"\n",
    "sms_2_path = \"hdfs:///data/landing/gx_pnt/mck_dmp_score/04_features/sms_2/fea_commercial_text_messaging.parquet/weekstart={weekstart}\"\n",
    "\n",
    "master_path = \"hdfs:///data/landing/gx_pnt/mck_dmp_score/05_model_input/scoring_master.parquet/weekstart={weekstart}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaffold_df = spark.read.parquet(scaffold_path.format(weekstart=weekstart))\n",
    "internet_app_usage_df = spark.read.parquet(internet_app_usage_path.format(weekstart=weekstart))\n",
    "revenue_df = spark.read.parquet(revenue_path.format(weekstart=weekstart))\n",
    "recharge_1_df = spark.read.parquet(recharge_1_path.format(weekstart=weekstart))\n",
    "recharge_2_df = spark.read.parquet(recharge_2_path.format(weekstart=weekstart))\n",
    "recharge_3_df = spark.read.parquet(recharge_3_path.format(weekstart=weekstart))\n",
    "handset_df = spark.read.parquet(handset_path.format(weekstart=weekstart))\n",
    "voice_calls_df = spark.read.parquet(voice_calls_path.format(weekstart=weekstart))\n",
    "internet_usage_df = spark.read.parquet(internet_usage_path.format(weekstart=weekstart))\n",
    "cust_prof_df = spark.read.parquet(cust_prof_path.format(weekstart=weekstart))\n",
    "sms_1_df = spark.read.parquet(sms_1_path.format(weekstart=weekstart))\n",
    "sms_2_df = spark.read.parquet(sms_2_path.format(weekstart=weekstart))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = (\n",
    "    scaffold_df.join(handset_df, [\"msisdn\"], how=\"left\")\n",
    "    .join(internet_app_usage_df, [\"msisdn\"], how=\"left\")\n",
    "    .join(internet_usage_df, [\"msisdn\"], how=\"left\")\n",
    "    .join(recharge_1_df, [\"msisdn\"], how=\"left\")\n",
    "    .join(recharge_2_df, [\"msisdn\"], how=\"left\")\n",
    "    .join(recharge_3_df, [\"msisdn\"], how=\"left\")\n",
    "    .join(revenue_df, [\"msisdn\"], how=\"left\")\n",
    "    .join(sms_1_df, [\"msisdn\"], how=\"left\")\n",
    "    .join(sms_2_df, [\"msisdn\"], how=\"left\")\n",
    "    .join(voice_calls_df, [\"msisdn\"], how=\"left\")\n",
    "    .join(cust_prof_df, [\"msisdn\"], how=\"left\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mode \"overwrite\" is removed from the write statement to prevent the accidental removal of old master files.\n",
    "\n",
    "master_df.write.parquet(master_path.format(weekstart=weekstart))\n",
    "# master_df.write.mode(\"overwrite\").parquet(master_path.format(weekstart=weekstart))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
