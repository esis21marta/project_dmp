{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uplift Models for Promoters Campaigns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "During the Promoters Campaigns, the monthly cashflow effect of sending promoters to an outlet may vary from being very positive to very negative. A negative effect implies that money was spent in sending the promoters but actually the monthly sales diminished, which is not desirable for Tsel or for the outlet. So we want to send promoters only to outlets where we expect the outcome will be at least enough positive to justify the investment.\n",
    "\n",
    "Uplift models can be used to target the best outlets to send the promoters. In this notebook, we will load the data from the Promoters Pilot to make an uplift model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is based on the \"causalml\" library from Uber and the data processing based on typical data science libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from causalml.dataset import synthetic_data\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import r2_score, classification_report, confusion_matrix, accuracy_score\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "import math as math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Promoters Pilot table and organice it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset contains the results of the change in cashflow from february to march for the Promoters Pilot Test and Control Groups.\n",
    "\n",
    "The Control Group was created by finding for each Test outlet, another random outlet having the same classification, type and region. This means both groups have the same size (but we will see later that due to temporal reasons the sizes of both groups will become different)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PP_experiment_df = pd.read_csv('Promoters Pilot input table v2.txt')\n",
    "PP_experiment_df.rename(columns={'Outlet_id':'outlet_id'},inplace=True)\n",
    "#PP_experiment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PP_experiment_df = PP_experiment_df.drop(columns=['Cashflow_feb','Cashflow_march_1_29'])\n",
    "PP_experiment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of test and control outlets\n",
    "outlets_list = PP_experiment_df['outlet_id'].tolist()\n",
    "len(outlets_list) # Number of outlets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load outlets master table of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This table is used as the input for the Reseller's Model, but we will use it to add features to the Test and Control groups outlets. The features will be useful during the modelling stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = pd.read_csv('../../../data/reseller/07_model_output/gridsearchcv/ra_mck_int_gridsearchcv_master_prepared.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#master_df.head()\n",
    "len(master_df)\n",
    "len(master_df.outlet_id.unique())\n",
    "len(master_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check how many Test and Control outlets in master table of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not at outlets in the Test and Control groups are present in the master table, so we will check how many there are. Note that this causes the Test and Control groups to have smaller and different sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make list of all outlets in master table of features\n",
    "master_outlets_list = master_df.outlet_id.unique().tolist()\n",
    "len(master_outlets_list) # Outlets in master table of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many Test and Control outlets in master table\n",
    "Exp_outlets_in_master_df = PP_experiment_df[PP_experiment_df['outlet_id'].isin(master_outlets_list)]\n",
    "len(Exp_outlets_in_master_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for only Test/Treatment outlets\n",
    "Exp_outlets_in_master_1_df = Exp_outlets_in_master_df.loc[Exp_outlets_in_master_df['Treatment'] == 1]\n",
    "len(Exp_outlets_in_master_1_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for only Control/Non-Treatment outlets\n",
    "Exp_outlets_in_master_0_df = Exp_outlets_in_master_df.loc[Exp_outlets_in_master_df['Treatment'] == 0]\n",
    "len(Exp_outlets_in_master_0_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter master table of features by outlets list (Test and Control)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we filter the master table of features by the Test and Control outlets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PP_features_df = master_df[master_df['outlet_id'].isin(outlets_list)]\n",
    "len(PP_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of columns\n",
    "len(PP_features_df.columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean NA columns just in case\n",
    "PP_features_df = PP_features_df.dropna(axis=1)\n",
    "len(PP_features_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attach master table of features to Promoters Pilot table\n",
    "\n",
    "Now both tables are joined to produce a Promoters Pilot master table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PP_master_df = PP_experiment_df.join(PP_features_df.set_index('outlet_id'), on='outlet_id')\n",
    "PP_master_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PP_master_df = PP_master_df.dropna(axis=0)\n",
    "len(PP_master_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(PP_features_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create target variable y (many approaches/possibilities or target variable included)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PP_master_df['Delta_feb_mar'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cash = PP_master_df['Delta_feb_mar'].tolist()\n",
    "PP_master_df['target_class1'] = -1\n",
    "target1 = PP_master_df['target_class1'].tolist()\n",
    "for i in range(0,len(cash)):\n",
    "    if cash[i] > 6.835000e+05:\n",
    "        target1[i] = 4\n",
    "    elif cash[i] <= 6.835000e+05 and cash[i] > -1.254000e+06:\n",
    "        target1[i] = 3\n",
    "    elif cash[i] <= -1.254000e+06 and cash[i] > -3.588500e+06:  \n",
    "        target1[i] = 2\n",
    "    elif cash[i] <= -3.588500e+06:\n",
    "        target1[i] = 1\n",
    "    else:\n",
    "        print('Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign target variable\n",
    "PP_master_df['target_class'] = target1\n",
    "y = PP_master_df['target_class1'] # Here the targe variable is being chosen from 3 options\n",
    "len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment = PP_master_df['Treatment']\n",
    "len(treatment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create features X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for relevant columns\n",
    "PP_master_df.columns[0:20].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevant columns\n",
    "df0 = PP_master_df.iloc[:,1:2]\n",
    "df1 = PP_master_df.iloc[:,3:6]\n",
    "df2 = PP_master_df.iloc[:,10:11]\n",
    "df3 = PP_master_df.iloc[:,12:2108]\n",
    "df4 = PP_master_df.iloc[:,2213:2371]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.concat([df0,df1,df2,df3,df4], axis=1)\n",
    "#x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = []\n",
    "for j in range(0,len(x.columns)):\n",
    "    if x.dtypes[j] == 'float64' or x.dtypes[j] == 'int64':\n",
    "        columns.append(x.columns[j])\n",
    "print(len(columns))\n",
    "#columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x[columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest model to define subset of x features to use in uplift model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = RandomForestClassifier()\n",
    "regressor.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chooose top variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Variables = pd.Series(x.columns)\n",
    "Feature_importances = pd.Series(regressor.feature_importances_)\n",
    "Feature_importances_dic = {'Variable': Variables, \"Feature_importance\": Feature_importances}\n",
    "Feature_importances_df = pd.DataFrame(Feature_importances_dic)\n",
    "Feature_importance_sorted_df = Feature_importances_df.sort_values(by=\"Feature_importance\", ascending=False)\n",
    "#Feature_importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fis = Feature_importances_df.sort_values(by=\"Feature_importance\", ascending=False)\n",
    "fis.iloc[0:100,:]\n",
    "#fis['Variable'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_ranked = fis['Variable'].tolist()\n",
    "top_vars = vars_ranked[0:50]\n",
    "#top_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = x[top_vars]\n",
    "#X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for possible sample bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_check_bias = x.drop(columns=['Promoter_days'])\n",
    "x_train, x_test, t_train, t_test = train_test_split(x_check_bias, treatment, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = RandomForestClassifier()\n",
    "regressor.fit(x_train,t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_pred = regressor.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(t_test,t_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(t_test,t_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(t_test,t_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Variables = pd.Series(x.columns)\n",
    "Feature_importances = pd.Series(regressor.feature_importances_)\n",
    "Feature_importances_dic = {'Variable': Variables, \"Feature_importance\": Feature_importances}\n",
    "Feature_importances_df = pd.DataFrame(Feature_importances_dic)\n",
    "Feature_importance_sorted_df = Feature_importances_df.sort_values(by=\"Feature_importance\", ascending=False)\n",
    "#Feature_importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fis = Feature_importances_df.sort_values(by=\"Feature_importance\", ascending=False)\n",
    "fis.iloc[0:10,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uplift modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from causalml.inference.meta import BaseTRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from causalml.inference.meta import XGBTRegressor\n",
    "\n",
    "# Approach 1\n",
    "y = PP_master_df['Delta_feb_mar']\n",
    "# Approach 2\n",
    "#y = PP_master_df['Percentage_change_feb_mar']\n",
    "# Approach 3\n",
    "#y = PP_master_df['Cashflow_march_1_29']\n",
    "\n",
    "PP_master_df['target'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([\n",
    "    pd.DataFrame({\"y\": y, \"treatment\": treatment}),\n",
    "    pd.DataFrame(X)],\n",
    "    axis = 1\n",
    ")\n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms of control and target\n",
    "fig, axes = plt.subplots(1,2)\n",
    "Hist_test = PP_master_df[PP_master_df.Treatment == 1]\n",
    "Hist_control = PP_master_df[PP_master_df.Treatment == 0]\n",
    "Hist_test.hist('target',bins=30,ax=axes[0])\n",
    "Hist_control.hist('target',bins=30,ax=axes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check variances of control and target\n",
    "#Hist_test.hist('target',bins=30,ax=axes[0])\n",
    "#Hist_control.hist('target',bins=30,ax=axes[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, treatment_train, treatment_test = train_test_split(X, y, treatment, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training T-learner on train\n",
    "learner_t = XGBTRegressor(learner=XGBRegressor(random_state=42))\n",
    "learner_t.fit(X=X_train, treatment=treatment_train, y=y_train)\n",
    "\n",
    "## Get predictions, on the test set\n",
    "t_pred = learner_t.predict(X=X_test)\n",
    "#uplift, outcome_c, outcome_t = learner_t.predict(X=X_test, return_components=True)\n",
    "\n",
    "## Aggregating everything on a dataframe\n",
    "df = pd.DataFrame({'y': y_test,\n",
    "                   'w': treatment_test,\n",
    "                   'T-Learner': t_pred.reshape(-1)\n",
    "                  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lift plot for cummulative raw sales due to campaign\n",
    "from causalml.metrics import plot\n",
    "plot(df,kind='lift', outcome_col='y', treatment_col='w',figsize=(10, 3.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qini plot (where uplift is in y-axis, which is test - control for the given segment)\n",
    "plot(df,kind='qini', outcome_col='y', treatment_col='w',figsize=(10, 3.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from causalml.metrics import auuc_score, qini_score\n",
    "print('\\nQINI Score\\n',qini_score(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('AUUC:\\n',auuc_score(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importances using SHAP\n",
    "import shap\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Raw SHAP values\n",
    "shap_values = learner_t.get_shap_values(X=X_test,\n",
    "                                        tau=learner_t.predict(X_test),\n",
    "                                        #we may specify the exact model to be used as additonal one\n",
    "                                        model_tau_feature = RandomForestRegressor(n_estimators=100))\n",
    "#shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP importance plot\n",
    "learner_t.plot_shap_values(X=X_test, tau=learner_t.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
