{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from causalml.dataset import synthetic_data\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import r2_score, classification_report, confusion_matrix, accuracy_score\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "import math as math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and organice it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load experiment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PP_experiment_df = pd.read_csv('Promoters Pilot input table v2.txt')\n",
    "PP_experiment_df.rename(columns={'Outlet_id':'outlet_id'},inplace=True)\n",
    "len(PP_experiment_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PP_experiment_df = PP_experiment_df.drop(columns=['Cashflow_feb','Cashflow_march_1_29'])\n",
    "PP_experiment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define outlets list\n",
    "outlets_list = PP_experiment_df['outlet_id'].tolist()\n",
    "len(outlets_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load master table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = pd.read_csv('../../../data/reseller/05_model_input/master_table/ra_master_table.csv')\n",
    "#master_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove un-used columns\n",
    "master_df = master_df.drop(columns=['month','fea_outlet_string_location_bts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(master_df)\n",
    "len(master_df.outlet_id.unique())\n",
    "len(master_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for experiment outlets not in master table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_outlets_list = master_df.outlet_id.unique().tolist()\n",
    "len(master_outlets_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Exp_outlets_in_master_df = PP_experiment_df[PP_experiment_df['outlet_id'].isin(master_outlets_list)]\n",
    "len(Exp_outlets_in_master_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Exp_outlets_in_master_1_df = Exp_outlets_in_master_df.loc[Exp_outlets_in_master_df['Treatment'] == 1]\n",
    "len(Exp_outlets_in_master_1_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Exp_outlets_in_master_0_df = Exp_outlets_in_master_df.loc[Exp_outlets_in_master_df['Treatment'] == 0]\n",
    "len(Exp_outlets_in_master_0_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter master table by outlets list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PP_features_df = master_df[master_df['outlet_id'].isin(outlets_list)]\n",
    "len(PP_features_df)\n",
    "len(PP_features_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(PP_features_df.outlet_id.unique())\n",
    "#PP_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PP_features_df = PP_features_df.dropna(axis=1)\n",
    "len(PP_features_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PP_master_df = PP_experiment_df.join(PP_features_df.set_index('outlet_id'), on='outlet_id')\n",
    "#PP_master_df.head()\n",
    "len(PP_master_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PP_master_df = PP_master_df.dropna()\n",
    "len(PP_master_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create target variable and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PP_master_df['target_class'] = -1\n",
    "len(PP_master_df['target_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PP_master_df['Delta_feb_mar'].describe()\n",
    "#PP_master_df['Percentage_change_feb_mar'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cash = PP_master_df['Delta_feb_mar'].tolist()\n",
    "target = PP_master_df['target_class'].tolist()\n",
    "for i in range(0,len(cash)):\n",
    "    if cash[i] > 7.240000e+05:\n",
    "        target[i] = 4\n",
    "    elif cash[i] <= 7.240000e+05 and cash[i] > -1.230000e+06:\n",
    "        target[i] = 3\n",
    "    elif cash[i] <= -1.230000e+06 and cash[i] > -3.792500e+06:  \n",
    "        target[i] = 2\n",
    "    elif cash[i] <= -3.792500e+06:\n",
    "        target[i] = 1\n",
    "    else:\n",
    "        print('Error')\n",
    "#cash = PP_master_df['Percentage_change_feb_mar'].tolist()\n",
    "#target = PP_master_df['target_class'].tolist()\n",
    "#for i in range(0,len(cash)):\n",
    "#    if cash[i] > 5.109689:\n",
    "#        target[i] = 4\n",
    "#    elif cash[i] <= 5.109689 and cash[i] > -7.770335:\n",
    "#        target[i] = 3\n",
    "#    elif cash[i] <= -7.770335 and cash[i] > -19.744084:  \n",
    "#        target[i] = 2\n",
    "#    elif cash[i] <= -19.744084:\n",
    "#        target[i] = 1\n",
    "#    else:\n",
    "#        print('Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PP_master_df['target_class'] = target\n",
    "PP_master_df['target_class']\n",
    "#len(PP_master_df['target_class'])\n",
    "#PP_master_df\n",
    "len(PP_master_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment = PP_master_df['Treatment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = PP_master_df['target_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PP_master_df.columns[1053:1400].tolist() # At 347 start geospatial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PP_master_filtered_df = PP_master_df.iloc[:,347:1053]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(PP_master_df.columns)\n",
    "len(PP_master_filtered_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = PP_master_filtered_df.drop(columns=['fea_outlet_decimal_total_cashflow_mkios_pv_mean_past_3m'])\n",
    "#x = PP_master_filtered_df\n",
    "#x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(x.dtypes)\n",
    "len(x.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = []\n",
    "for j in range(0,len(x.columns)):\n",
    "    if x.dtypes[j] == 'float64' or x.dtypes[j] == 'int64':\n",
    "        columns.append(x.columns[j])\n",
    "print(len(columns))\n",
    "#columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x[columns]\n",
    "#x = x.dropna(axis=1)\n",
    "#x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest model to calculate feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = RandomForestClassifier()\n",
    "regressor.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Variables = pd.Series(x.columns)\n",
    "Feature_importances = pd.Series(regressor.feature_importances_)\n",
    "Feature_importances_dic = {'Variable': Variables, \"Feature_importance\": Feature_importances}\n",
    "Feature_importances_df = pd.DataFrame(Feature_importances_dic)\n",
    "Feature_importance_sorted_df = Feature_importances_df.sort_values(by=\"Feature_importance\", ascending=False)\n",
    "#Feature_importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fis = Feature_importances_df.sort_values(by=\"Feature_importance\", ascending=False)\n",
    "fis.iloc[0:100,:]\n",
    "#fis['Variable'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_ranked = fis['Variable'].tolist()\n",
    "top_vars = vars_ranked[0:50]\n",
    "#top_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = x[top_vars]\n",
    "#X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uplift modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from causalml.inference.meta import BaseTRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from causalml.inference.meta import XGBTRegressor\n",
    "\n",
    "y = PP_master_df['Delta_feb_mar']\n",
    "\n",
    "data = pd.concat([\n",
    "    pd.DataFrame({\"y\": y, \"treatment\": treatment}),\n",
    "    pd.DataFrame(X)],\n",
    "    axis = 1\n",
    ")\n",
    "#data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_tlearner = BaseTRegressor(learner=XGBRegressor(random_state=42))\n",
    "\n",
    "xgb_tlearner.fit(X=X, y=y, treatment=treatment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_tlearner.predict(X=X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uplift, outcome_c, outcome_t = xgb_tlearner.predict(X=X, return_components=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(uplift)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, treatment_train, treatment_test = train_test_split(X, y, treatment, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training T-learner on train\n",
    "learner_t = XGBTRegressor(learner=XGBRegressor(random_state=42))\n",
    "learner_t.fit(X=X_train, treatment=treatment_train, y=y_train)\n",
    "\n",
    "## Get predictions, on the test set\n",
    "t_pred = learner_t.predict(X=X_test)\n",
    "uplift, outcome_c, outcome_t = learner_t.predict(X=X_test, return_components=True)\n",
    "\n",
    "## Aggregating everything on a dataframe\n",
    "df = pd.DataFrame({'y': y_test,\n",
    "                   'w': treatment_test,\n",
    "                   'T-Learner': t_pred.reshape(-1)\n",
    "                   #'Actual': tau_test\n",
    "                  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(uplift)\n",
    "len(uplift[uplift >=0])\n",
    "np.sum(uplift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from causalml.metrics import plot\n",
    "## Plotting the 3 types of uplift curve. \n",
    "## If `treatment_effect_col` is provided (the true uplift) it uses that to \n",
    "## order the population by the highest score. Otherwise it uses the Treatment score.\n",
    "plot(df,kind='qini', outcome_col='y', treatment_col='w',figsize=(10, 3.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
